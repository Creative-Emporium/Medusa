{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MedusaConfig {\n",
       "  \"base_model_name_or_path\": \"/home/camus/.cache/huggingface/hub/models--meta-llama--Meta-Llama-3-8B/snapshots/62bd457b6fe961a42a631306577e622c83876cb6\",\n",
       "  \"medusa_num_heads\": 5,\n",
       "  \"medusa_num_layers\": 1,\n",
       "  \"transformers_version\": \"4.41.2\",\n",
       "  \"version\": \"2\"\n",
       "}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from medusa.model.medusa_model import MedusaConfig\n",
    "\n",
    "\n",
    "config = MedusaConfig.from_pretrained('./train/0625_medusa_mlp_Meta-Llama-3-8B-Instruct_medusa_5_lr_0.0001_layers_1')\n",
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Conversation(name='llama-3', system_template='<|start_header_id|>system<|end_header_id|>\\n\\n{system_message}<|eot_id|>', system_message='', roles=('user', 'assistant'), messages=[], offset=0, sep_style=<SeparatorStyle.LLAMA3: 8>, sep='', sep2=None, stop_str='<|eot_id|>', stop_token_ids=[128001, 128009], max_image_size_mb=None)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from fastchat.model.model_adapter import get_conversation_template\n",
    "\n",
    "\n",
    "conv = get_conversation_template(config.base_model_name_or_path)\n",
    "conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "805"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "\n",
    "data = json.load(open('./assets/alpaca_eval.json'))\n",
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dataset': 'helpful_base',\n",
       " 'instruction': 'What are the names of some famous actors that started their careers on Broadway?',\n",
       " 'output': 'Some famous actors that started their careers on Broadway include: \\n1. Hugh Jackman \\n2. Meryl Streep \\n3. Denzel Washington \\n4. Julia Roberts \\n5. Christopher Walken \\n6. Anthony Rapp \\n7. Audra McDonald \\n8. Nathan Lane \\n9. Sarah Jessica Parker \\n10. Lin-Manuel Miranda',\n",
       " 'generator': 'text_davinci_003'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample = data[0]\n",
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<|begin_of_text|><|start_header_id|>user<|end_header_id|>\\n\\nWhat are the names of some famous actors that started their careers on Broadway?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv.messages = []\n",
    "conv.append_message(conv.roles[0], sample[\"instruction\"])\n",
    "conv.append_message(conv.roles[1], \"\")\n",
    "\n",
    "prompt = conv.get_prompt()\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Loading checkpoint shards: 100%|██████████| 4/4 [00:05<00:00,  1.45s/it]\n",
      "Some weights of MedusaModelLlama were not initialized from the model checkpoint at /home/camus/.cache/huggingface/hub/models--meta-llama--Meta-Llama-3-8B/snapshots/62bd457b6fe961a42a631306577e622c83876cb6 and are newly initialized: ['medusa_head.0.0.linear.bias', 'medusa_head.0.0.linear.weight', 'medusa_head.0.1.weight', 'medusa_head.1.0.linear.bias', 'medusa_head.1.0.linear.weight', 'medusa_head.1.1.weight', 'medusa_head.2.0.linear.bias', 'medusa_head.2.0.linear.weight', 'medusa_head.2.1.weight', 'medusa_head.3.0.linear.bias', 'medusa_head.3.0.linear.weight', 'medusa_head.3.1.weight', 'medusa_head.4.0.linear.bias', 'medusa_head.4.0.linear.weight', 'medusa_head.4.1.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MedusaModelLlama(\n",
       "  (model): LlamaModel(\n",
       "    (embed_tokens): Embedding(128256, 4096)\n",
       "    (layers): ModuleList(\n",
       "      (0-31): 32 x LlamaDecoderLayer(\n",
       "        (self_attn): LlamaAttention(\n",
       "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (k_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "          (v_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (rotary_emb): LlamaRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): LlamaMLP(\n",
       "          (gate_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
       "          (up_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
       "          (down_proj): Linear(in_features=14336, out_features=4096, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): LlamaRMSNorm()\n",
       "        (post_attention_layernorm): LlamaRMSNorm()\n",
       "      )\n",
       "    )\n",
       "    (norm): LlamaRMSNorm()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=4096, out_features=128256, bias=False)\n",
       "  (medusa_head): ModuleList(\n",
       "    (0-4): 5 x Sequential(\n",
       "      (0): ResBlock(\n",
       "        (linear): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "        (act): SiLU()\n",
       "      )\n",
       "      (1): Linear(in_features=4096, out_features=128256, bias=False)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from medusa.model.medusa_model import MedusaModel\n",
    "\n",
    "\n",
    "model = MedusaModel.from_pretrained(\n",
    "    './train/0625_medusa_mlp_Meta-Llama-3-8B-Instruct_medusa_5_lr_0.0001_layers_1',\n",
    "    medusa_num_heads=5,\n",
    "    torch_dtype=torch.float16,\n",
    "    low_cpu_mem_usage=True,\n",
    "    device_map=\"auto\",\n",
    ")\n",
    "tokenizer = model.get_tokenizer()\n",
    "\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[128000, 128000, 128006,    882, 128007,    271,   3923,    527,    279,\n",
       "           5144,    315,   1063,  11495,  20142,    430,   3940,    872,  31133,\n",
       "            389,  37776,     30, 128009, 128006,  78191, 128007,    271]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ids = tokenizer([prompt]).input_ids\n",
    "input_ids = torch.as_tensor(input_ids).cuda()\n",
    "input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from medusa.model.kv_cache import initialize_past_key_values\n",
    "from medusa.model.utils import reset_medusa_mode\n",
    "\n",
    "\n",
    "past_key_values, past_key_values_data, current_length_data = initialize_past_key_values(model.base_model)\n",
    "model.past_key_values = past_key_values\n",
    "model.past_key_values_data = past_key_values_data\n",
    "model.current_length_data = current_length_data\n",
    "\n",
    "model.current_length_data.zero_()\n",
    "reset_medusa_mode(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([5, 1, 26, 128256]),\n",
       " BaseModelOutputWithPast(last_hidden_state=tensor([[[ 4.0078, -0.5010, -1.9932,  ..., -3.7461,  0.8423,  2.6992],\n",
       "          [ 4.0078, -0.5010, -1.9932,  ..., -3.7461,  0.8423,  2.6992],\n",
       "          [ 2.1016, -0.5078, -1.7432,  ...,  0.0694,  1.4648, -0.9570],\n",
       "          ...,\n",
       "          [ 0.7495,  0.1599,  3.6270,  ...,  2.4043, -0.1870,  0.8550],\n",
       "          [-1.3467, -1.1621,  1.2295,  ...,  0.3220, -1.3652,  1.5195],\n",
       "          [-0.6021,  1.4229,  4.0508,  ...,  0.8022,  0.1729,  0.6201]]],\n",
       "        device='cuda:0', dtype=torch.float16), past_key_values=(None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None), hidden_states=None, attentions=None),\n",
       " torch.Size([1, 26, 128256]))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with torch.inference_mode():\n",
    "\tmedusa_logits, outputs, logits = model(\n",
    "\t\tinput_ids, past_key_values=past_key_values, output_orig=True, medusa_forward=True\n",
    "\t)\n",
    "\n",
    "medusa_logits.shape, outputs, logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([5, 1, 20]),\n",
       " torch.Size([5, 1, 20]),\n",
       " tensor([[[  6553,  30783,  97049,  81813,  12152,  60812,  35948,  28033,\n",
       "             6455,  93277,  85174,  68799,  62353,  75046, 126489, 115320,\n",
       "            85165,  49820, 109946,  29285]],\n",
       " \n",
       "         [[ 61236,  37390,  33318,  59865, 124901,  78783,  30653,   6545,\n",
       "           114540,  87370,   1160, 126758, 125714,  68845,    294,  64895,\n",
       "            27206,  39817,   4411, 119565]],\n",
       " \n",
       "         [[ 25063,  99170,  40558,  77186,  80921,    285,  78408, 117483,\n",
       "            79795,  56068,  47971,  55309,  19549,  87357,  43742,  51086,\n",
       "            14950,  69071,  66109,  80492]],\n",
       " \n",
       "         [[ 95892,  81706, 111001,  92549,  12849,  60000, 100809,   3569,\n",
       "            11085,  68411,  44347,  84774,  99830,  76173,  56963,  58317,\n",
       "           101262,  41727,  95236, 110330]],\n",
       " \n",
       "         [[ 89963,  37407,  22819, 100229, 117782, 119140,  40855,   8911,\n",
       "            36413, 113467, 112399, 126557,  12415,  17055, 114597,  65348,\n",
       "            90721, 116463,  99030, 115254]]], device='cuda:0'))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_, medusa_topk = medusa_logits[...,-1,:].topk(20, dim=-1)\n",
    "_.shape, medusa_topk.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['iforn, Payload, æŃ³, Ġipad, ĠCanadian, (delete, .Dep, ĠLegend, si, ĠHLS, ayah, ISK, Ġcasi, Hyper, ĠÚ¯Ø°Ø§Ø±ÛĮ, é£², ĠNEG, Ġscreenshots, ĠNhá»¯ng, aveled',\n",
       " 'ĠCater, Ġrhythm, Ġdevastating, .TAG, Ġhá»©, lsa, -Ch, .web, ĠÐ²Ð¾Ð·Ð´ÐµÐ¹ÑģÑĤÐ², Ġconfiscated, Ġlist, ãĤĤãģªãģĦ, Ġê³łëł¤, ĠCunning, Ġd, Ġhailed, ĠHorn, -defined, Ġmor, ÑĢÐ¸Ð¸',\n",
       " '-set, ĠBinaryTree, Ġbees, ĉReturns, Ġkitty, is, Ġesi, :::|, Ace, Slug, ¾ç¤º, Ġbargaining, shall, ĠQSize, Removed, connections, CLU, Grant, .Temp, Ġterrestrial',\n",
       " '):?>Ċ, svp, Æ°á»Ŀn, _blocking, Ġcompute, _returns, Ġquan, ++)Ċ, .java, avl, ĠisActive, ĠcreateContext, igmatic, ByExample, [state, ĠÐ¶, Ð°Ð½Ñĸ, =l, ()?;Ċ, ĠÑĢÐµÐ°Ðº',\n",
       " '>{\", ĠFabric, OTAL, idders, ĠÙĨØ³Ø¨Ø©, adla, ĠDepart, Ġappend, Ġprima, ĠAnadolu, ĠãĦ, ãĢįãĢĤ, Ð¹, Ġhydro, ìĹĺ, MethodInfo, Ġforfeiture, ĠÑĨÑĸÐ», à¸µà¸¢, Ġà¤Ńà¤Ĺ']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[', '.join([tokenizer._tokenizer.id_to_token(id) for id in medusa_topk[i, 0]]) for i in range(5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[2]], device='cuda:0'), '#')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_id = logits[:, -1:].argmax(dim=-1)\n",
    "input_id, tokenizer._tokenizer.id_to_token(input_id.item())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
