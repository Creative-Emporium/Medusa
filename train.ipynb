{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/camus/work/Medusa/env/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LlamaConfig {\n",
       "  \"_name_or_path\": \"/home/camus/.cache/huggingface/hub/models--meta-llama--Meta-Llama-3-8B/snapshots/62bd457b6fe961a42a631306577e622c83876cb6\",\n",
       "  \"architectures\": [\n",
       "    \"LlamaForCausalLM\"\n",
       "  ],\n",
       "  \"attention_bias\": false,\n",
       "  \"attention_dropout\": 0.0,\n",
       "  \"bos_token_id\": 128000,\n",
       "  \"eos_token_id\": 128001,\n",
       "  \"hidden_act\": \"silu\",\n",
       "  \"hidden_size\": 4096,\n",
       "  \"initializer_range\": 0.02,\n",
       "  \"intermediate_size\": 14336,\n",
       "  \"max_position_embeddings\": 8192,\n",
       "  \"mlp_bias\": false,\n",
       "  \"model_type\": \"llama\",\n",
       "  \"num_attention_heads\": 32,\n",
       "  \"num_hidden_layers\": 32,\n",
       "  \"num_key_value_heads\": 8,\n",
       "  \"pretraining_tp\": 1,\n",
       "  \"rms_norm_eps\": 1e-05,\n",
       "  \"rope_scaling\": null,\n",
       "  \"rope_theta\": 500000.0,\n",
       "  \"tie_word_embeddings\": false,\n",
       "  \"torch_dtype\": \"bfloat16\",\n",
       "  \"transformers_version\": \"4.41.2\",\n",
       "  \"use_cache\": true,\n",
       "  \"vocab_size\": 128256\n",
       "}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import transformers\n",
    "\n",
    "from medusa.train.train_legacy import ModelArguments, DataArguments, TrainingArguments\n",
    "\n",
    "\n",
    "model_args = ModelArguments(\n",
    "\tmodel_name_or_path=os.path.expanduser('~/.cache/huggingface/hub/models--meta-llama--Meta-Llama-3-8B/snapshots/62bd457b6fe961a42a631306577e622c83876cb6'),\n",
    ")\n",
    "\n",
    "data_args = DataArguments(\n",
    "\tdata_path=os.path.expanduser('~/data/ShareGPT_Vicuna_unfiltered/shareGPT-llama3-8B.json'),\n",
    "\tlazy_preprocess=True,\n",
    ")\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "\toutput_dir='./train/test',\n",
    "\tmedusa_num_heads=5,\n",
    "\tmedusa_num_layers=1,\n",
    ")\n",
    "\n",
    "config = transformers.AutoConfig.from_pretrained(\n",
    "\tmodel_args.model_name_or_path,\n",
    "\tcache_dir=training_args.cache_dir,\n",
    ")\n",
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8192, 2048)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "orig_ctx_len = getattr(config, \"max_position_embeddings\", None)\n",
    "orig_ctx_len, training_args.model_max_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "config.use_cache = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, None, '<|end_of_text|>')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = transformers.AutoTokenizer.from_pretrained(\n",
    "    model_args.model_name_or_path,\n",
    "    cache_dir=training_args.cache_dir,\n",
    "    model_max_length=training_args.model_max_length,\n",
    "    padding_side=\"right\",\n",
    "    use_fast=True,\n",
    ")\n",
    "\n",
    "tokenizer.pad_token, tokenizer.unk_token, tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [[128000, 2028, 374, 264, 1296], [128000, 19217, 128001, 128001, 128001]], 'attention_mask': [[1, 1, 1, 1, 1], [1, 1, 0, 0, 0]]}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer([\"This is a test\", \"secondary\"], padding=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[128000,\n",
       " 128006,\n",
       " 882,\n",
       " 128007,\n",
       " 271,\n",
       " 2028,\n",
       " 374,\n",
       " 264,\n",
       " 1296,\n",
       " 128009,\n",
       " 128006,\n",
       " 78191,\n",
       " 128007,\n",
       " 271]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.apply_chat_template([{\"role\": \"user\", \"content\": \"This is a test\"}])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 4/4 [00:01<00:00,  2.09it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LlamaForCausalLM(\n",
       "  (model): LlamaModel(\n",
       "    (embed_tokens): Embedding(128256, 4096)\n",
       "    (layers): ModuleList(\n",
       "      (0-31): 32 x LlamaDecoderLayer(\n",
       "        (self_attn): LlamaSdpaAttention(\n",
       "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (k_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "          (v_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (rotary_emb): LlamaRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): LlamaMLP(\n",
       "          (gate_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
       "          (up_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
       "          (down_proj): Linear(in_features=14336, out_features=4096, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): LlamaRMSNorm()\n",
       "        (post_attention_layernorm): LlamaRMSNorm()\n",
       "      )\n",
       "    )\n",
       "    (norm): LlamaRMSNorm()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=4096, out_features=128256, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "\n",
    "model = transformers.LlamaForCausalLM.from_pretrained(\n",
    "    model_args.model_name_or_path,\n",
    "    config=config,\n",
    "    cache_dir=training_args.cache_dir,\n",
    "    torch_dtype=torch.bfloat16,\n",
    ")\n",
    "\n",
    "for param in model.base_model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MedusaModel(\n",
       "  (base_model): LlamaForCausalLM(\n",
       "    (model): LlamaModel(\n",
       "      (embed_tokens): Embedding(128256, 4096)\n",
       "      (layers): ModuleList(\n",
       "        (0-31): 32 x LlamaDecoderLayer(\n",
       "          (self_attn): LlamaSdpaAttention(\n",
       "            (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "            (k_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "            (v_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "            (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "            (rotary_emb): LlamaRotaryEmbedding()\n",
       "          )\n",
       "          (mlp): LlamaMLP(\n",
       "            (gate_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
       "            (up_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
       "            (down_proj): Linear(in_features=14336, out_features=4096, bias=False)\n",
       "            (act_fn): SiLU()\n",
       "          )\n",
       "          (input_layernorm): LlamaRMSNorm()\n",
       "          (post_attention_layernorm): LlamaRMSNorm()\n",
       "        )\n",
       "      )\n",
       "      (norm): LlamaRMSNorm()\n",
       "    )\n",
       "    (lm_head): Linear(in_features=4096, out_features=128256, bias=False)\n",
       "  )\n",
       "  (medusa_head): ModuleList(\n",
       "    (0-4): 5 x Sequential(\n",
       "      (0): ResBlock(\n",
       "        (linear): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "        (act): SiLU()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from medusa.model.medusa_model_legacy import MedusaModel\n",
    "\n",
    "\n",
    "medusa_lm_head = MedusaModel(\n",
    "    model,\n",
    "    medusa_num_heads=training_args.medusa_num_heads,\n",
    "    medusa_num_layers=training_args.medusa_num_layers,\n",
    "    base_model_name_or_path=model_args.model_name_or_path,\n",
    ")\n",
    "medusa_lm_head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train_dataset': <medusa.train.train_legacy.LazySupervisedDataset at 0x723f580643d0>,\n",
       " 'eval_dataset': None}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from medusa.train.train_legacy import make_supervised_data_module\n",
    "\n",
    "\n",
    "data_module = make_supervised_data_module(tokenizer=tokenizer, data_args=data_args)\n",
    "data_module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataloader.DataLoader at 0x723f47d3fc10>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader, RandomSampler\n",
    "from transformers.trainer_utils import seed_worker\n",
    "from transformers.data.data_collator import DataCollatorWithPadding\n",
    "\n",
    "\n",
    "default_collator = DataCollatorWithPadding(tokenizer)\n",
    "\n",
    "dataloader_params = {\n",
    "\t\"batch_size\": 1,\n",
    "\t\"collate_fn\": default_collator,\n",
    "\t\"num_workers\": 1,\n",
    "\t\"pin_memory\": training_args.dataloader_pin_memory,\n",
    "\t\"persistent_workers\": training_args.dataloader_persistent_workers,\n",
    "\t\"sampler\": RandomSampler(data_module['train_dataset']),\n",
    "\t\"drop_last\": training_args.dataloader_drop_last,\n",
    "\t\"worker_init_fn\": seed_worker,\n",
    "\t\"prefetch_factor\": training_args.dataloader_prefetch_factor,\n",
    "}\n",
    "\n",
    "loader = DataLoader(data_module['train_dataset'], **dataloader_params)\n",
    "loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "it = iter(loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[128000, 128000, 128006,  ...,    775,    341,    415]]), 'labels': tensor([[  -100, 128000, 128006,  ...,    775,    341,    415]]), 'attention_mask': tensor([[True, True, True,  ..., True, True, True]])}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch = next(it)\n",
    "batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 2048]), torch.Size([1, 2048]), torch.Size([1, 2048]))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch['input_ids'].shape, batch['labels'].shape, batch['attention_mask'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|begin_of_text|><|begin_of_text|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "How would I generate a trusted certificate?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "Generating a trusted certificate involves creating a public key certificate that can be trusted by a browser or other application. Here are the general steps:\n",
      "\n",
      "**Option 1: Self-Signed Certificate**\n",
      "\n",
      "You can generate a self-signed certificate using a tool like OpenSSL. This certificate will be trusted by default by your own application, but it will not be trusted by browsers or other applications.\n",
      "\n",
      "1. Install OpenSSL on your system.\n",
      "2. Run the following command to generate a private key and a self-signed certificate:\n",
      "```\n",
      "openssl req -x509 -newkey rsa:2048 -nodes -keyout example.com.key -out example.com.crt -subj \"/C=US/ST=State/L=Locality/O=Organization/CN=example.com\"\n",
      "```\n",
      "This command generates a 2048-bit RSA private key and a self-signed certificate with the subject \"example.com\".\n",
      "\n",
      "**Option 2: CA-Signed Certificate**\n",
      "\n",
      "If you want a certificate that is trusted by browsers and other applications, you need to get it signed by a trusted Certificate Authority (CA). Here are the steps:\n",
      "\n",
      "1. Choose a CA: Research and select a reputable CA that issues trusted certificates. Some popular options include Let's Encrypt, GlobalSign, and DigiCert.\n",
      "2. Generate a Certificate Signing Request (CSR): Use OpenSSL to generate a CSR that contains your public key and other identifying information.\n",
      "```\n",
      "openssl req -newkey rsa:2048 -nodes -keyout example.com.key -out example.com.csr -subj \"/C=US/ST=State/L=Locality/O=Organization/CN=example.com\"\n",
      "```\n",
      "3. Send the CSR to the CA: Submit the CSR to the CA, along with any required information and fees.\n",
      "4. Obtain the signed certificate: The CA will review your request and issue a signed certificate, which will be sent to you.\n",
      "\n",
      "**Example: Let's Encrypt**\n",
      "\n",
      "Let's Encrypt is a popular CA that offers free, automated certificate issuance. You can use the following command to generate a CSR and obtain a signed certificate:\n",
      "```\n",
      "sudo certbot certonly --webroot -w /path/to/webroot -d example.com\n",
      "```\n",
      "This command uses the certbot tool to generate a CSR and obtain a signed certificate from Let's Encrypt. The `--webroot` option specifies the path to your webroot directory, and the `-d` option specifies the domain name for which you want to obtain a certificate.\n",
      "\n",
      "**Conclusion**\n",
      "\n",
      "Generating a trusted certificate involves creating a public key certificate that can be trusted by a browser or other application. You can generate a self-signed certificate using OpenSSL or obtain a signed certificate from a trusted Certificate Authority like Let's Encrypt.<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "John, Mike and Christine all have their own websites that are hosted independently on different servers. When John updates his website, Christine wants that update to be pushed to her server and a feed section of her website called \"my friend's webpages\" to be updated with a message saying \"John at http://www.johnworld.net just updated '/about me' and a link to the page updated\n",
      "\n",
      "How would they implement this system?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "What a fun problem!\n",
      "\n",
      "To implement this system, John, Mike, and Christine will need to use a combination of technologies. Here's a suggested approach:\n",
      "\n",
      "**Components**\n",
      "\n",
      "1. **Server-side scripting**: Each website will need a server-side scripting language (e.g., PHP, Python, Ruby) to interact with the other servers and update the \"my friend's webpages\" section.\n",
      "2. **Webhooks**: A webhook is an HTTP callback that notifies a server of an event (in this case, a website update). Webhooks will be used to notify Christine's server when John updates his website.\n",
      "3. **API**: An API will be created to facilitate communication between the servers. API endpoints will be used to send and receive data, such as website updates and notifications.\n",
      "4. **Database**: A database will be used to store information about the websites, such as their URLs, updated pages, and notification settings.\n",
      "\n",
      "**Implementation**\n",
      "\n",
      "**Step 1: Set up the API**\n",
      "\n",
      "* Create an API endpoint on each server to receive and process updates.\n",
      "* Define the API endpoint's behavior:\n",
      "\t+ Receive an update from John's server (e.g., a JSON object containing the updated page URL and content).\n",
      "\t+ Store the update in the database.\n",
      "\t+ Send a notification to Christine's server using a webhook.\n",
      "\n",
      "**Step 2: Implement the webhook**\n",
      "\n",
      "* On Christine's server, create a webhook endpoint to receive notifications from John's server.\n",
      "* Define the webhook's behavior:\n",
      "\t+ Receive a notification from John's server.\n",
      "\t+ Extract the update information (e.g., page URL and content) from the notification.\n",
      "\t+ Update the \"my friend's webpages\" section on Christine's website with the new information.\n",
      "\n",
      "**Step 3: Configure the server-side scripting**\n",
      "\n",
      "* On each server, write server-side code to:\n",
      "\t+ Monitor for updates on the website.\n",
      "\t+ Send an API request to the API endpoint on the other server when an update is detected.\n",
      "\t+ Handle API responses (e.g., update successful or failed).\n",
      "\n",
      "**Example Code**\n",
      "\n",
      "Here's a simplified example in PHP:\n",
      "```php\n",
      "// John's server (johnworld.net)\n",
      "// Update API endpoint\n",
      "function updateApi() {\n",
      "  $update = array('page' => '/about-me', 'content' => 'New content!');\n",
      "  $curl = curl_init('https://christine.com/api/update');\n",
      "  curl_setopt($curl, CURLOPT_RETURNTRANSFER, true);\n",
      "  curl_setopt($curl, CURLOPT_POSTFIELDS, json_encode($update));\n",
      "  $response = curl_exec($curl);\n",
      "  curl_close($curl);\n",
      "}\n",
      "\n",
      "// Christine's server (christine.com)\n",
      "// Webhook endpoint\n",
      "function webhook() {\n",
      "  $notification = json_decode(file_get_contents('php://input'), true);\n",
      "  $pageUrl = $notification['page'];\n",
      "  $pageContent = $notification['content'];\n",
      "  // Update \"my friend's webpages\" section\n",
      "  $fp = fopen('my-friend-webpages.txt', 'w');\n",
      "  fwrite($fp, \"{$pageUrl} - {$pageContent}\\n\");\n",
      "  fclose($fp);\n",
      "}\n",
      "\n",
      "// API endpoint\n",
      "function apiUpdate() {\n",
      "  $update = json_decode(file_get_contents('php://input'), true);\n",
      "  // Store update in database\n",
      "  // Send notification to Christine's server using webhook\n",
      "  $webhookUrl = 'https://christine.com/webhook';\n",
      "  $ch = curl_init($webhookUrl);\n",
      "  curl_setopt($ch, CURLOPT_RETURNTRANSFER, true);\n",
      "  curl_setopt($ch, CURLOPT_POSTFIELDS, json_encode($update));\n",
      "  $response = curl_exec($ch);\n",
      "  curl_close($ch);\n",
      "}\n",
      "```\n",
      "**Security Considerations**\n",
      "\n",
      "* Ensure the API endpoints and webhooks are properly secured with authentication and authorization mechanisms.\n",
      "* Use HTTPS to encrypt data transmitted between servers.\n",
      "* Validate and sanitize input data to prevent malicious code execution or data tampering.\n",
      "\n",
      "This is a basic example, and you may need to adapt it to your specific requirements. Additionally, you'll need to consider factors like scalability, reliability, and performance when implementing this system.<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "Please share the nodejs architecture for this system<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "Here's a suggested Node.js architecture for the system:\n",
      "\n",
      "**Components**\n",
      "\n",
      "1. **Web Servers**: Each website will have its own web server (e.g., Express.js, Koa.js) to serve the website's content.\n",
      "2. **API Gateway**: A central API gateway will be used to receive updates from one website and forward them to the other website(s). This can be implemented using a Node.js framework like Express.js or Koa.js.\n",
      "3. **Notification Service**: A notification service will be used to send notifications from the API gateway to the website(s) that need to be updated. This can be implemented using a messaging queue like Redis or RabbitMQ.\n",
      "4. **Database**: A database will be used to store information about the websites, such as their URLs, updated pages, and notification settings.\n",
      "\n",
      "**Architecture**\n",
      "\n",
      "**Step 1: Set up the API Gateway**\n",
      "\n",
      "* Create a new Node.js project for the API gateway.\n",
      "* Install the required dependencies (e.g., Express.js, Redis).\n",
      "* Define the API endpoints:\n",
      "\t+ `/update`: Receive an update from one website and forward it to the other website(s).\n",
      "\t+ `/notifications`: Send notifications to the website(s) that need to be updated.\n",
      "\n",
      "**Step 2: Implement the Notification Service**\n",
      "\n",
      "* Install a messaging queue like Redis or RabbitMQ.\n",
      "* Use the queue to send notifications from the API gateway to the website(s) that need to be updated.\n",
      "* Implement a listener on the website(s) to receive notifications from the queue.\n",
      "\n",
      "**Step 3: Configure the Web Servers**\n",
      "\n",
      "* On each website, install a Node.js framework like Express.js or Koa.js.\n",
      "* Define the server-side code to:\n",
      "\t+ Monitor for updates on the website.\n",
      "\t+ Send an API request to the API gateway when an update is detected.\n",
      "\t+ Handle API responses (e.g., update successful or failed).\n",
      "\n",
      "**Example Code**\n",
      "\n",
      "Here's a simplified example in Node.js:\n",
      "```javascript\n",
      "// API Gateway (api-gateway.js)\n",
      "const express = require('express');\n",
      "const redis = require('redis');\n",
      "const app = express();\n",
      "\n",
      "app.use(express.json());\n",
      "\n",
      "const redisClient = redis.createClient();\n",
      "\n",
      "app.post('/update', (req, res) => {\n",
      "  const update = req.body;\n",
      "  redisClient.lpush('updates', JSON.stringify(update));\n",
      "  res.send({ message: 'Update received' });\n",
      "});\n",
      "\n",
      "app.get('/notifications', (req, res) => {\n",
      "  redisClient.lrange('updates', 0, -1, (err, updates) => {\n",
      "    if (err) {\n",
      "      res.status(500).send({ message: 'Error retrieving updates' });\n",
      "    } else {\n",
      "     \n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.decode(batch['input_ids'][0], skip_special_tokens=False, spaces_between_special_tokens=False, clean_up_tokenization_spaces=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[-100,\n",
       "  128000,\n",
       "  128006,\n",
       "  -100,\n",
       "  128007,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  128009,\n",
       "  128006,\n",
       "  -100,\n",
       "  128007,\n",
       "  -100,\n",
       "  74414,\n",
       "  264,\n",
       "  22542,\n",
       "  16125,\n",
       "  18065,\n",
       "  6968,\n",
       "  264,\n",
       "  586,\n",
       "  1401,\n",
       "  16125,\n",
       "  430,\n",
       "  649,\n",
       "  387,\n",
       "  22542,\n",
       "  555,\n",
       "  264,\n",
       "  7074,\n",
       "  477,\n",
       "  1023,\n",
       "  3851,\n",
       "  13,\n",
       "  5810,\n",
       "  527,\n",
       "  279,\n",
       "  4689,\n",
       "  7504,\n",
       "  1473,\n",
       "  334,\n",
       "  5454,\n",
       "  220,\n",
       "  16,\n",
       "  25,\n",
       "  10323,\n",
       "  6354,\n",
       "  1571,\n",
       "  32502,\n",
       "  57277,\n",
       "  2675,\n",
       "  649,\n",
       "  7068,\n",
       "  264,\n",
       "  659,\n",
       "  93653,\n",
       "  16125,\n",
       "  1701,\n",
       "  264,\n",
       "  5507,\n",
       "  1093,\n",
       "  66717,\n",
       "  13,\n",
       "  1115,\n",
       "  16125,\n",
       "  690,\n",
       "  387,\n",
       "  22542,\n",
       "  555,\n",
       "  1670,\n",
       "  555,\n",
       "  701,\n",
       "  1866,\n",
       "  3851,\n",
       "  11,\n",
       "  719,\n",
       "  433,\n",
       "  690,\n",
       "  539,\n",
       "  387,\n",
       "  22542,\n",
       "  555,\n",
       "  33957,\n",
       "  477,\n",
       "  1023,\n",
       "  8522,\n",
       "  382,\n",
       "  16,\n",
       "  13,\n",
       "  19796,\n",
       "  66717,\n",
       "  389,\n",
       "  701,\n",
       "  1887,\n",
       "  627,\n",
       "  17,\n",
       "  13,\n",
       "  6588,\n",
       "  279,\n",
       "  2768,\n",
       "  3290,\n",
       "  311,\n",
       "  7068,\n",
       "  264,\n",
       "  879,\n",
       "  1401,\n",
       "  323,\n",
       "  264,\n",
       "  659,\n",
       "  93653,\n",
       "  16125,\n",
       "  512,\n",
       "  14196,\n",
       "  4077,\n",
       "  54712,\n",
       "  4326,\n",
       "  482,\n",
       "  87,\n",
       "  12448,\n",
       "  482,\n",
       "  943,\n",
       "  798,\n",
       "  69670,\n",
       "  25,\n",
       "  7854,\n",
       "  23,\n",
       "  482,\n",
       "  20606,\n",
       "  482,\n",
       "  798,\n",
       "  412,\n",
       "  3187,\n",
       "  916,\n",
       "  4840,\n",
       "  482,\n",
       "  412,\n",
       "  3187,\n",
       "  916,\n",
       "  94969,\n",
       "  482,\n",
       "  79114,\n",
       "  3605,\n",
       "  34,\n",
       "  28,\n",
       "  2078,\n",
       "  14,\n",
       "  790,\n",
       "  28,\n",
       "  1423,\n",
       "  7586,\n",
       "  28,\n",
       "  9330,\n",
       "  2786,\n",
       "  17991,\n",
       "  28,\n",
       "  42674,\n",
       "  11547,\n",
       "  45,\n",
       "  28,\n",
       "  8858,\n",
       "  916,\n",
       "  702,\n",
       "  14196,\n",
       "  4077,\n",
       "  2028,\n",
       "  3290,\n",
       "  27983,\n",
       "  264,\n",
       "  220,\n",
       "  7854,\n",
       "  23,\n",
       "  15615,\n",
       "  46741,\n",
       "  879,\n",
       "  1401,\n",
       "  323,\n",
       "  264,\n",
       "  659,\n",
       "  93653,\n",
       "  16125,\n",
       "  449,\n",
       "  279,\n",
       "  3917,\n",
       "  330,\n",
       "  8858,\n",
       "  916,\n",
       "  11690,\n",
       "  334,\n",
       "  5454,\n",
       "  220,\n",
       "  17,\n",
       "  25,\n",
       "  9362,\n",
       "  6354,\n",
       "  1571,\n",
       "  32502,\n",
       "  57277,\n",
       "  2746,\n",
       "  499,\n",
       "  1390,\n",
       "  264,\n",
       "  16125,\n",
       "  430,\n",
       "  374,\n",
       "  22542,\n",
       "  555,\n",
       "  33957,\n",
       "  323,\n",
       "  1023,\n",
       "  8522,\n",
       "  11,\n",
       "  499,\n",
       "  1205,\n",
       "  311,\n",
       "  636,\n",
       "  433,\n",
       "  8667,\n",
       "  555,\n",
       "  264,\n",
       "  22542,\n",
       "  32502,\n",
       "  22677,\n",
       "  320,\n",
       "  5158,\n",
       "  570,\n",
       "  5810,\n",
       "  527,\n",
       "  279,\n",
       "  7504,\n",
       "  1473,\n",
       "  16,\n",
       "  13,\n",
       "  22991,\n",
       "  264,\n",
       "  9362,\n",
       "  25,\n",
       "  8483,\n",
       "  323,\n",
       "  3373,\n",
       "  264,\n",
       "  56940,\n",
       "  9362,\n",
       "  430,\n",
       "  4819,\n",
       "  22542,\n",
       "  35537,\n",
       "  13,\n",
       "  4427,\n",
       "  5526,\n",
       "  2671,\n",
       "  2997,\n",
       "  6914,\n",
       "  596,\n",
       "  56559,\n",
       "  11,\n",
       "  8121,\n",
       "  7412,\n",
       "  11,\n",
       "  323,\n",
       "  423,\n",
       "  30637,\n",
       "  38034,\n",
       "  627,\n",
       "  17,\n",
       "  13,\n",
       "  20400,\n",
       "  264,\n",
       "  32502,\n",
       "  88524,\n",
       "  6274,\n",
       "  320,\n",
       "  71122,\n",
       "  1680,\n",
       "  5560,\n",
       "  66717,\n",
       "  311,\n",
       "  7068,\n",
       "  264,\n",
       "  64076,\n",
       "  430,\n",
       "  5727,\n",
       "  701,\n",
       "  586,\n",
       "  1401,\n",
       "  323,\n",
       "  1023,\n",
       "  25607,\n",
       "  2038,\n",
       "  627,\n",
       "  14196,\n",
       "  4077,\n",
       "  54712,\n",
       "  4326,\n",
       "  482,\n",
       "  943,\n",
       "  798,\n",
       "  69670,\n",
       "  25,\n",
       "  7854,\n",
       "  23,\n",
       "  482,\n",
       "  20606,\n",
       "  482,\n",
       "  798,\n",
       "  412,\n",
       "  3187,\n",
       "  916,\n",
       "  4840,\n",
       "  482,\n",
       "  412,\n",
       "  3187,\n",
       "  916,\n",
       "  522,\n",
       "  15444,\n",
       "  482,\n",
       "  79114,\n",
       "  3605,\n",
       "  34,\n",
       "  28,\n",
       "  2078,\n",
       "  14,\n",
       "  790,\n",
       "  28,\n",
       "  1423,\n",
       "  7586,\n",
       "  28,\n",
       "  9330,\n",
       "  2786,\n",
       "  17991,\n",
       "  28,\n",
       "  42674,\n",
       "  11547,\n",
       "  45,\n",
       "  28,\n",
       "  8858,\n",
       "  916,\n",
       "  702,\n",
       "  14196,\n",
       "  4077,\n",
       "  18,\n",
       "  13,\n",
       "  11244,\n",
       "  279,\n",
       "  64076,\n",
       "  311,\n",
       "  279,\n",
       "  9362,\n",
       "  25,\n",
       "  30270,\n",
       "  279,\n",
       "  64076,\n",
       "  311,\n",
       "  279,\n",
       "  9362,\n",
       "  11,\n",
       "  3235,\n",
       "  449,\n",
       "  904,\n",
       "  2631,\n",
       "  2038,\n",
       "  323,\n",
       "  12718,\n",
       "  627,\n",
       "  19,\n",
       "  13,\n",
       "  64524,\n",
       "  279,\n",
       "  8667,\n",
       "  16125,\n",
       "  25,\n",
       "  578,\n",
       "  9362,\n",
       "  690,\n",
       "  3477,\n",
       "  701,\n",
       "  1715,\n",
       "  323,\n",
       "  4360,\n",
       "  264,\n",
       "  8667,\n",
       "  16125,\n",
       "  11,\n",
       "  902,\n",
       "  690,\n",
       "  387,\n",
       "  3288,\n",
       "  311,\n",
       "  499,\n",
       "  382,\n",
       "  334,\n",
       "  13617,\n",
       "  25,\n",
       "  6914,\n",
       "  596,\n",
       "  56559,\n",
       "  57277,\n",
       "  10267,\n",
       "  596,\n",
       "  56559,\n",
       "  374,\n",
       "  264,\n",
       "  5526,\n",
       "  9362,\n",
       "  430,\n",
       "  6209,\n",
       "  1949,\n",
       "  11,\n",
       "  28598,\n",
       "  16125,\n",
       "  67599,\n",
       "  13,\n",
       "  1472,\n",
       "  649,\n",
       "  1005,\n",
       "  279,\n",
       "  2768,\n",
       "  3290,\n",
       "  311,\n",
       "  7068,\n",
       "  264,\n",
       "  64076,\n",
       "  323,\n",
       "  6994,\n",
       "  264,\n",
       "  8667,\n",
       "  16125,\n",
       "  512,\n",
       "  14196,\n",
       "  4077,\n",
       "  19413,\n",
       "  2847,\n",
       "  6465,\n",
       "  2847,\n",
       "  3323,\n",
       "  1198,\n",
       "  2984,\n",
       "  2959,\n",
       "  482,\n",
       "  86,\n",
       "  611,\n",
       "  2398,\n",
       "  33529,\n",
       "  22561,\n",
       "  2959,\n",
       "  482,\n",
       "  67,\n",
       "  3187,\n",
       "  916,\n",
       "  198,\n",
       "  14196,\n",
       "  4077,\n",
       "  2028,\n",
       "  3290,\n",
       "  5829,\n",
       "  279,\n",
       "  2847,\n",
       "  6465,\n",
       "  5507,\n",
       "  311,\n",
       "  7068,\n",
       "  264,\n",
       "  64076,\n",
       "  323,\n",
       "  6994,\n",
       "  264,\n",
       "  8667,\n",
       "  16125,\n",
       "  505,\n",
       "  6914,\n",
       "  596,\n",
       "  56559,\n",
       "  13,\n",
       "  578,\n",
       "  1595,\n",
       "  313,\n",
       "  2984,\n",
       "  2959,\n",
       "  63,\n",
       "  3072,\n",
       "  30202,\n",
       "  279,\n",
       "  1853,\n",
       "  311,\n",
       "  701,\n",
       "  3566,\n",
       "  2959,\n",
       "  6352,\n",
       "  11,\n",
       "  323,\n",
       "  279,\n",
       "  94897,\n",
       "  67,\n",
       "  63,\n",
       "  3072,\n",
       "  30202,\n",
       "  279,\n",
       "  8106,\n",
       "  836,\n",
       "  369,\n",
       "  902,\n",
       "  499,\n",
       "  1390,\n",
       "  311,\n",
       "  6994,\n",
       "  264,\n",
       "  16125,\n",
       "  382,\n",
       "  334,\n",
       "  44534,\n",
       "  57277,\n",
       "  74414,\n",
       "  264,\n",
       "  22542,\n",
       "  16125,\n",
       "  18065,\n",
       "  6968,\n",
       "  264,\n",
       "  586,\n",
       "  1401,\n",
       "  16125,\n",
       "  430,\n",
       "  649,\n",
       "  387,\n",
       "  22542,\n",
       "  555,\n",
       "  264,\n",
       "  7074,\n",
       "  477,\n",
       "  1023,\n",
       "  3851,\n",
       "  13,\n",
       "  1472,\n",
       "  649,\n",
       "  7068,\n",
       "  264,\n",
       "  659,\n",
       "  93653,\n",
       "  16125,\n",
       "  1701,\n",
       "  66717,\n",
       "  477,\n",
       "  6994,\n",
       "  264,\n",
       "  8667,\n",
       "  16125,\n",
       "  505,\n",
       "  264,\n",
       "  22542,\n",
       "  32502,\n",
       "  22677,\n",
       "  1093,\n",
       "  6914,\n",
       "  596,\n",
       "  56559,\n",
       "  13,\n",
       "  128009,\n",
       "  128006,\n",
       "  882,\n",
       "  128007,\n",
       "  271,\n",
       "  13379,\n",
       "  11,\n",
       "  11519,\n",
       "  323,\n",
       "  46993,\n",
       "  682,\n",
       "  617,\n",
       "  872,\n",
       "  1866,\n",
       "  13335,\n",
       "  430,\n",
       "  527,\n",
       "  21685,\n",
       "  29235,\n",
       "  389,\n",
       "  2204,\n",
       "  16692,\n",
       "  13,\n",
       "  3277,\n",
       "  3842,\n",
       "  9013,\n",
       "  813,\n",
       "  3997,\n",
       "  11,\n",
       "  46993,\n",
       "  6944,\n",
       "  430,\n",
       "  2713,\n",
       "  311,\n",
       "  387,\n",
       "  15753,\n",
       "  311,\n",
       "  1077,\n",
       "  3622,\n",
       "  323,\n",
       "  264,\n",
       "  5510,\n",
       "  3857,\n",
       "  315,\n",
       "  1077,\n",
       "  3997,\n",
       "  2663,\n",
       "  330,\n",
       "  2465,\n",
       "  4333,\n",
       "  596,\n",
       "  3566,\n",
       "  11014,\n",
       "  1,\n",
       "  311,\n",
       "  387,\n",
       "  6177,\n",
       "  449,\n",
       "  264,\n",
       "  1984,\n",
       "  5605,\n",
       "  330,\n",
       "  13379,\n",
       "  520,\n",
       "  1795,\n",
       "  1129,\n",
       "  2185,\n",
       "  1190,\n",
       "  3180,\n",
       "  14957,\n",
       "  5181,\n",
       "  1120,\n",
       "  6177,\n",
       "  3434,\n",
       "  9274,\n",
       "  757,\n",
       "  6,\n",
       "  323,\n",
       "  264,\n",
       "  2723,\n",
       "  311,\n",
       "  279,\n",
       "  2199,\n",
       "  6177,\n",
       "  271,\n",
       "  4438,\n",
       "  1053,\n",
       "  814,\n",
       "  4305,\n",
       "  420,\n",
       "  1887,\n",
       "  30,\n",
       "  128009,\n",
       "  128006,\n",
       "  78191,\n",
       "  128007,\n",
       "  271,\n",
       "  3923,\n",
       "  264,\n",
       "  2523,\n",
       "  3575,\n",
       "  2268,\n",
       "  1271,\n",
       "  4305,\n",
       "  420,\n",
       "  1887,\n",
       "  11,\n",
       "  3842,\n",
       "  11,\n",
       "  11519,\n",
       "  11,\n",
       "  323,\n",
       "  46993,\n",
       "  690,\n",
       "  1205,\n",
       "  311,\n",
       "  1005,\n",
       "  264,\n",
       "  10824,\n",
       "  315,\n",
       "  14645,\n",
       "  13,\n",
       "  5810,\n",
       "  596,\n",
       "  264,\n",
       "  12090,\n",
       "  5603,\n",
       "  1473,\n",
       "  334,\n",
       "  10660,\n",
       "  57277,\n",
       "  16,\n",
       "  13,\n",
       "  3146,\n",
       "  5592,\n",
       "  25034,\n",
       "  68522,\n",
       "  96618,\n",
       "  9062,\n",
       "  3997,\n",
       "  690,\n",
       "  1205,\n",
       "  264,\n",
       "  3622,\n",
       "  25034,\n",
       "  68522,\n",
       "  4221,\n",
       "  320,\n",
       "  68,\n",
       "  1326,\n",
       "  2637,\n",
       "  13420,\n",
       "  11,\n",
       "  13325,\n",
       "  11,\n",
       "  24658,\n",
       "  8,\n",
       "  311,\n",
       "  16681,\n",
       "  449,\n",
       "  279,\n",
       "  1023,\n",
       "  16692,\n",
       "  323,\n",
       "  2713,\n",
       "  279,\n",
       "  330,\n",
       "  2465,\n",
       "  4333,\n",
       "  596,\n",
       "  3566,\n",
       "  11014,\n",
       "  1,\n",
       "  3857,\n",
       "  627,\n",
       "  17,\n",
       "  13,\n",
       "  3146,\n",
       "  6109,\n",
       "  39660,\n",
       "  96618,\n",
       "  362,\n",
       "  76368,\n",
       "  374,\n",
       "  459,\n",
       "  10339,\n",
       "  4927,\n",
       "  430,\n",
       "  97689,\n",
       "  264,\n",
       "  3622,\n",
       "  315,\n",
       "  459,\n",
       "  1567,\n",
       "  320,\n",
       "  258,\n",
       "  420,\n",
       "  1162,\n",
       "  11,\n",
       "  264,\n",
       "  3997,\n",
       "  2713,\n",
       "  570,\n",
       "  5000,\n",
       "  39660,\n",
       "  690,\n",
       "  387,\n",
       "  1511,\n",
       "  311,\n",
       "  15820,\n",
       "  46993,\n",
       "  596,\n",
       "  3622,\n",
       "  994,\n",
       "  3842,\n",
       "  9013,\n",
       "  813,\n",
       "  3997,\n",
       "  627,\n",
       "  18,\n",
       "  13,\n",
       "  3146,\n",
       "  7227,\n",
       "  96618,\n",
       "  1556,\n",
       "  5446,\n",
       "  690,\n",
       "  387,\n",
       "  3549,\n",
       "  311,\n",
       "  28696,\n",
       "  10758,\n",
       "  1990,\n",
       "  279,\n",
       "  16692,\n",
       "  13,\n",
       "  5446,\n",
       "  37442,\n",
       "  690,\n",
       "  387,\n",
       "  1511,\n",
       "  311,\n",
       "  3708,\n",
       "  323,\n",
       "  5371,\n",
       "  828,\n",
       "  11,\n",
       "  1778,\n",
       "  439,\n",
       "  3997,\n",
       "  9013,\n",
       "  323,\n",
       "  22736,\n",
       "  627,\n",
       "  19,\n",
       "  13,\n",
       "  3146,\n",
       "  6116,\n",
       "  96618,\n",
       "  362,\n",
       "  4729,\n",
       "  690,\n",
       "  387,\n",
       "  1511,\n",
       "  311,\n",
       "  3637,\n",
       "  2038,\n",
       "  922,\n",
       "  279,\n",
       "  13335,\n",
       "  11,\n",
       "  1778,\n",
       "  439,\n",
       "  872,\n",
       "  36106,\n",
       "  11,\n",
       "  6177,\n",
       "  6959,\n",
       "  11,\n",
       "  323,\n",
       "  11801,\n",
       "  5110,\n",
       "  382,\n",
       "  334,\n",
       "  37950,\n",
       "  57277,\n",
       "  334,\n",
       "  8468,\n",
       "  220,\n",
       "  16,\n",
       "  25,\n",
       "  2638,\n",
       "  709,\n",
       "  279,\n",
       "  5446,\n",
       "  57277,\n",
       "  9,\n",
       "  4324,\n",
       "  459,\n",
       "  5446,\n",
       "  15233,\n",
       "  389,\n",
       "  1855,\n",
       "  3622,\n",
       "  311,\n",
       "  5371,\n",
       "  323,\n",
       "  1920,\n",
       "  9013,\n",
       "  627,\n",
       "  9,\n",
       "  19127,\n",
       "  279,\n",
       "  5446,\n",
       "  15233,\n",
       "  596,\n",
       "  7865,\n",
       "  512,\n",
       "  197,\n",
       "  10,\n",
       "  38522,\n",
       "  459,\n",
       "  2713,\n",
       "  505,\n",
       "  3842,\n",
       "  596,\n",
       "  3622,\n",
       "  320,\n",
       "  68,\n",
       "  1326,\n",
       "  2637,\n",
       "  264,\n",
       "  4823,\n",
       "  1665,\n",
       "  8649,\n",
       "  279,\n",
       "  6177,\n",
       "  2199,\n",
       "  5665,\n",
       "  323,\n",
       "  2262,\n",
       "  4390,\n",
       "  197,\n",
       "  10,\n",
       "  9307,\n",
       "  279,\n",
       "  2713,\n",
       "  304,\n",
       "  279,\n",
       "  4729,\n",
       "  627,\n",
       "  197,\n",
       "  10,\n",
       "  11244,\n",
       "  264,\n",
       "  11801,\n",
       "  311,\n",
       "  46993,\n",
       "  596,\n",
       "  3622,\n",
       "  1701,\n",
       "  264,\n",
       "  76368,\n",
       "  382,\n",
       "  334,\n",
       "  8468,\n",
       "  220,\n",
       "  17,\n",
       "  25,\n",
       "  32175,\n",
       "  279,\n",
       "  76368,\n",
       "  57277,\n",
       "  9,\n",
       "  1952,\n",
       "  46993,\n",
       "  596,\n",
       "  3622,\n",
       "  11,\n",
       "  1893,\n",
       "  264,\n",
       "  76368,\n",
       "  15233,\n",
       "  311,\n",
       "  5371,\n",
       "  22736,\n",
       "  505,\n",
       "  3842,\n",
       "  596,\n",
       "  3622,\n",
       "  627,\n",
       "  9,\n",
       "  19127,\n",
       "  279,\n",
       "  76368,\n",
       "  596,\n",
       "  7865,\n",
       "  512,\n",
       "  197,\n",
       "  10,\n",
       "  38522,\n",
       "  264,\n",
       "  11801,\n",
       "  505,\n",
       "  3842,\n",
       "  596,\n",
       "  3622,\n",
       "  627,\n",
       "  197,\n",
       "  10,\n",
       "  23673,\n",
       "  279,\n",
       "  2713,\n",
       "  2038,\n",
       "  320,\n",
       "  68,\n",
       "  1326,\n",
       "  2637,\n",
       "  2199,\n",
       "  5665,\n",
       "  323,\n",
       "  2262,\n",
       "  8,\n",
       "  505,\n",
       "  279,\n",
       "  11801,\n",
       "  627,\n",
       "  197,\n",
       "  10,\n",
       "  5666,\n",
       "  279,\n",
       "  330,\n",
       "  2465,\n",
       "  4333,\n",
       "  596,\n",
       "  3566,\n",
       "  11014,\n",
       "  1,\n",
       "  3857,\n",
       "  ...]]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch['labels'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "medusa_lm_head.medusa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MedusaModel(\n",
       "  (base_model): LlamaForCausalLM(\n",
       "    (model): LlamaModel(\n",
       "      (embed_tokens): Embedding(128256, 4096)\n",
       "      (layers): ModuleList(\n",
       "        (0-31): 32 x LlamaDecoderLayer(\n",
       "          (self_attn): LlamaSdpaAttention(\n",
       "            (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "            (k_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "            (v_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "            (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "            (rotary_emb): LlamaRotaryEmbedding()\n",
       "          )\n",
       "          (mlp): LlamaMLP(\n",
       "            (gate_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
       "            (up_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
       "            (down_proj): Linear(in_features=14336, out_features=4096, bias=False)\n",
       "            (act_fn): SiLU()\n",
       "          )\n",
       "          (input_layernorm): LlamaRMSNorm()\n",
       "          (post_attention_layernorm): LlamaRMSNorm()\n",
       "        )\n",
       "      )\n",
       "      (norm): LlamaRMSNorm()\n",
       "    )\n",
       "    (lm_head): Linear(in_features=4096, out_features=128256, bias=False)\n",
       "  )\n",
       "  (medusa_head): ModuleList(\n",
       "    (0-4): 5 x Sequential(\n",
       "      (0): ResBlock(\n",
       "        (linear): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "        (act): SiLU()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "medusa_lm_head.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 6.9062,  8.8125, 13.0000,  ..., -4.4375, -4.4375, -4.4375],\n",
       "          [ 6.9062,  8.8125, 13.0000,  ..., -4.4375, -4.4375, -4.4375],\n",
       "          [ 4.1250,  2.5781,  4.3438,  ..., -7.7188, -7.7188, -7.7188],\n",
       "          ...,\n",
       "          [ 7.8750,  7.5625,  2.5000,  ..., -1.7578, -1.7578, -1.7578],\n",
       "          [ 6.0312,  8.0000,  6.9375,  ..., -4.1250, -4.1250, -4.1250],\n",
       "          [ 0.3574, -2.2344, -1.0469,  ...,  0.3867,  0.3867,  0.3867]]],\n",
       "\n",
       "\n",
       "        [[[ 6.9062,  8.8125, 13.0000,  ..., -4.4375, -4.4375, -4.4375],\n",
       "          [ 6.9062,  8.8125, 13.0000,  ..., -4.4375, -4.4375, -4.4375],\n",
       "          [ 4.1250,  2.5781,  4.3438,  ..., -7.7188, -7.7188, -7.7188],\n",
       "          ...,\n",
       "          [ 7.9062,  7.5625,  2.4844,  ..., -1.7578, -1.7578, -1.7578],\n",
       "          [ 6.0312,  7.9688,  6.9375,  ..., -4.1250, -4.1250, -4.1250],\n",
       "          [ 0.3672, -2.2344, -1.0547,  ...,  0.3848,  0.3848,  0.3848]]],\n",
       "\n",
       "\n",
       "        [[[ 6.9375,  8.8125, 13.0000,  ..., -4.4375, -4.4375, -4.4375],\n",
       "          [ 6.9375,  8.8125, 13.0000,  ..., -4.4375, -4.4375, -4.4375],\n",
       "          [ 4.1250,  2.5781,  4.3438,  ..., -7.7188, -7.7188, -7.7188],\n",
       "          ...,\n",
       "          [ 7.8750,  7.5625,  2.4844,  ..., -1.7500, -1.7500, -1.7500],\n",
       "          [ 6.0312,  8.0000,  6.9375,  ..., -4.1250, -4.1250, -4.1250],\n",
       "          [ 0.3672, -2.2344, -1.0469,  ...,  0.3867,  0.3867,  0.3867]]],\n",
       "\n",
       "\n",
       "        [[[ 6.9062,  8.8125, 13.0000,  ..., -4.4375, -4.4375, -4.4375],\n",
       "          [ 6.9062,  8.8125, 13.0000,  ..., -4.4375, -4.4375, -4.4375],\n",
       "          [ 4.1250,  2.5781,  4.3438,  ..., -7.7188, -7.7188, -7.7188],\n",
       "          ...,\n",
       "          [ 7.8750,  7.5625,  2.5000,  ..., -1.7500, -1.7500, -1.7578],\n",
       "          [ 6.0312,  8.0000,  6.9062,  ..., -4.1250, -4.1250, -4.1250],\n",
       "          [ 0.3633, -2.2344, -1.0547,  ...,  0.3867,  0.3867,  0.3848]]],\n",
       "\n",
       "\n",
       "        [[[ 6.9062,  8.8125, 13.0000,  ..., -4.4375, -4.4375, -4.4375],\n",
       "          [ 6.9062,  8.8125, 13.0000,  ..., -4.4375, -4.4375, -4.4375],\n",
       "          [ 4.1250,  2.5781,  4.3438,  ..., -7.7188, -7.7188, -7.7188],\n",
       "          ...,\n",
       "          [ 7.8750,  7.5625,  2.4844,  ..., -1.7578, -1.7578, -1.7578],\n",
       "          [ 6.0312,  8.0000,  6.9062,  ..., -4.1250, -4.1250, -4.1250],\n",
       "          [ 0.3633, -2.2344, -1.0547,  ...,  0.3867,  0.3867,  0.3867]]]],\n",
       "       device='cuda:0', dtype=torch.bfloat16, grad_fn=<StackBackward0>)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits = medusa_lm_head(input_ids=batch[\"input_ids\"].to('cuda'), attention_mask=batch[\"attention_mask\"].to('cuda'))\n",
    "logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 1, 2048, 128256])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 2046, 128256]),\n",
       " tensor([[[ 6.9062,  8.8125, 13.0000,  ..., -4.4375, -4.4375, -4.4375],\n",
       "          [ 6.9062,  8.8125, 13.0000,  ..., -4.4375, -4.4375, -4.4375],\n",
       "          [ 4.1250,  2.5781,  4.3438,  ..., -7.7188, -7.7188, -7.7188],\n",
       "          ...,\n",
       "          [ 3.2969,  0.1553, -0.8789,  ...,  0.4414,  0.4414,  0.4414],\n",
       "          [ 6.8750,  6.8125,  4.3438,  ..., -2.5156, -2.5156, -2.5156],\n",
       "          [ 7.8750,  7.5625,  2.5000,  ..., -1.7578, -1.7578, -1.7578]]],\n",
       "        device='cuda:0', dtype=torch.bfloat16, grad_fn=<SliceBackward0>))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "medusa_logits = logits[0, :, :-2].contiguous()\n",
    "medusa_logits.shape, medusa_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 2046])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "medusa_labels = batch['labels'][..., 2:].contiguous()\n",
    "medusa_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2046, 128256]),\n",
       " tensor([[ 6.9062,  8.8125, 13.0000,  ..., -4.4375, -4.4375, -4.4375],\n",
       "         [ 6.9062,  8.8125, 13.0000,  ..., -4.4375, -4.4375, -4.4375],\n",
       "         [ 4.1250,  2.5781,  4.3438,  ..., -7.7188, -7.7188, -7.7188],\n",
       "         ...,\n",
       "         [ 3.2969,  0.1553, -0.8789,  ...,  0.4414,  0.4414,  0.4414],\n",
       "         [ 6.8750,  6.8125,  4.3438,  ..., -2.5156, -2.5156, -2.5156],\n",
       "         [ 7.8750,  7.5625,  2.5000,  ..., -1.7578, -1.7578, -1.7578]],\n",
       "        device='cuda:0', dtype=torch.bfloat16, grad_fn=<ViewBackward0>))"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "medusa_logits = medusa_logits.view(-1, logits.shape[-1])\n",
    "medusa_logits.shape, medusa_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2046]),\n",
       " tensor([128006,   -100, 128007,  ...,    775,    341,    415], device='cuda:0'))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "medusa_labels = medusa_labels.view(-1)\n",
    "medusa_labels = medusa_labels.to(medusa_logits.device)\n",
    "medusa_labels.shape, medusa_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(13., device='cuda:0', dtype=torch.bfloat16, grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch.nn import CrossEntropyLoss\n",
    "\n",
    "\n",
    "loss_fct = CrossEntropyLoss()\n",
    "loss_i = loss_fct(medusa_logits, medusa_labels)\n",
    "loss_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-100"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers.trainer_pt_utils import LabelSmoother\n",
    "\n",
    "LabelSmoother.ignore_index"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
